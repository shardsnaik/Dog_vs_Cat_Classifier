{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Dog_vs_Cat_Classifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.d_vs_c.funtions.comon_funtn import read_yaml, create_directories\n",
    "from main.d_vs_c.utils import *\n",
    "\n",
    "\n",
    "class ConfigManeger:\n",
    "\n",
    "    def __init__(self, config_path = config_file,\n",
    "                 param_path= params_file):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(param_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_folder])\n",
    "\n",
    "    def bilding_model_config(self):\n",
    "        config = self.config.preproccessed_data\n",
    "        # create_directories([config.preproccessed_data])\n",
    "\n",
    "        # bild_model = (\n",
    "        #     train_dir = Path(config.train_dir),\n",
    "        #     test_dir= Path(config.test_dir),\n",
    "        #     batch_size =self.params.batch_size,\n",
    "        #     seed= self.params.seed\n",
    "        # )\n",
    "        bild_model = {\n",
    "            'train_dir' : Path(config['train_dir']),\n",
    "            'test_dir': Path(config['test_dir']),\n",
    "            'batch_size': self.params['batch_size'],\n",
    "            'seed': self.params['seed'],\n",
    "            'image_size': self.params['image_size']\n",
    "        }\n",
    "        return bild_model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Datasets:\n",
    "    def __init__(self, config, params):\n",
    "        self.config = config\n",
    "        self.params = params\n",
    "\n",
    "    def datasets_(self):\n",
    "        train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = self.config['train_dir'],\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = self.params['batch_size'],\n",
    "    seed = self.params['seed'],\n",
    "    image_size = self.params['image_size']\n",
    ")\n",
    "        test_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory = self.config['test_dir'],\n",
    "    labels = 'inferred',\n",
    "    label_mode = 'int',\n",
    "    batch_size = self.params['batch_size'],\n",
    "    seed = self.params['seed'],\n",
    "    image_size = self.params['image_size']\n",
    ")\n",
    "        return train_ds, test_ds\n",
    "    \n",
    "\n",
    "    # Normalixe the images\n",
    "    @staticmethod\n",
    "    def process(images, label):\n",
    "        image = tf.image.resize(images, (256, 256))\n",
    "        image = tf.image.convert_image_dtype(images, tf.float32)\n",
    "        return images, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts_folder': 'artifacts', 'downloading_data': {'source_dir': 'artifacts/raw_data', 'source_URL': 'karakaggle/kaggle-cat-vs-dog-dataset'}, 'preproccessed_data': {'datasets_dir': 'artifacts/datasets', 'train_dir': 'artifacts/datasets/train', 'test_dir': 'artifacts/datasets/test'}, 'image_categories': ['train/Dog', 'train/Cat', 'test/Dog', 'test/Cat']}\n",
      "{'test_size': 0.2, 'random_state': 42, 'batch_size': 32, 'seed': 128, 'image_size': [256, 256], 'conv_first_layer': 32, 'conv_sec_layer': 64, 'conv_third_layer': 128, 'conv_fourth_layer': 256, 'kernel_size': [3, 3], 'input_shape': [256, 256, 3], 'pool_size': [2, 2], 'strides': 2, 'dropout_rate': 0.25, 'dense_first_layer': 128, 'dense_second_layer': 64, 'output_layer': 1, 'l2_regularization': 0.01, 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'metrics': 'accuracy'}\n",
      "[2024-11-19 00:14:45,780: INFO: comon_funtn: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19963 files belonging to 2 classes.\n",
      "Found 4986 files belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Datasets' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mmap(obj\u001b[38;5;241m.\u001b[39mprocess)\n\u001b[0;32m      7\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mmap(obj\u001b[38;5;241m.\u001b[39mprocess)\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m()\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Datasets' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "confi = ConfigManeger()\n",
    "config = confi.bilding_model_config()\n",
    "obj = Datasets(config, config)\n",
    "train, test = obj.datasets_()\n",
    "    \n",
    "train_ds = train.map(obj.process)\n",
    "test_ds = test.map(obj.process)\n",
    "model = obj.model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(self):\n",
    "        model_3 = Sequential()\n",
    "        \n",
    "        model_3.add(Conv2D(self.params['conv_first_layer'], kernel_size=self.params['kernel_size'], padding='valid', activation='relu', input_shape=(self.params['input_shape'])))\n",
    "        model_3.add(MaxPooling2D(pool_size=self.params['pool_size'], strides=self.params['strides'], padding='valid'))\n",
    "        model_3.add(Dropout(self.params['dropout_rate']))\n",
    "        \n",
    "        model_3.add(Conv2D(self.params['conv_sec_layer'], kernel_size=self.params['kernel_size'], padding='valid', activation='relu'))\n",
    "        model_3.add(MaxPooling2D(pool_size=self.params['pool_size'], strides=self.params['strides'], padding='valid'))\n",
    "        model_3.add(Dropout(self.params['dropout_rate']))\n",
    "        \n",
    "        model_3.add(Conv2D(self.params['conv_third_layer'], kernel_size=self.params['kernel_size'], padding='valid', activation='relu'))\n",
    "        model_3.add(MaxPooling2D(pool_size=self.params['pool_size'], strides=self.params['strides'], padding='valid'))\n",
    "        model_3.add(Dropout(self.params['dropout_rate']))\n",
    "        \n",
    "        model_3.add(Conv2D(self.params['conv_fourth_layer'], kernel_size=self.params['kernel_size'], padding='valid', activation='relu'))\n",
    "        model_3.add(MaxPooling2D(pool_size=self.params['pool_size'], strides=self.params['strides'], padding='valid'))\n",
    "        model_3.add(Dropout(self.params['dropout_rate']))\n",
    "        \n",
    "        model_3.add(Flatten())\n",
    "        \n",
    "        model_3.add(Dense(self.params['dense_first_layer'], activation='relu', kernel_regularizer=regularizers.l2(self.params['l2_regularization'])))\n",
    "        model_3.add(Dense(self.params['dense_second_layer'], activation='relu'))\n",
    "        model_3.add(Dense(self.params['output_layer'], activation='sigmoid'))\n",
    "\n",
    "         # Compile the model\n",
    "        model_3.compile(optimizer=self.params['optimizer'], loss=self.params['loss'], metrics=self.params['metrics'])\n",
    "        \n",
    "        return model_3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
