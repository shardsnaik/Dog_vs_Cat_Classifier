{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Dog_vs_Cat_Classifier'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.d_vs_c.funtions.comon_funtn import read_yaml, create_directories, save_json_file\n",
    "from main.d_vs_c.utils import *\n",
    "\n",
    "class ConfigManeger:\n",
    "    def __init__(self, config_path=config_file,\n",
    "                 param_path= params_file):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.parmas = read_yaml(params_file)\n",
    "\n",
    "        create_directories([self.config.artifacts_folder])\n",
    "\n",
    "    def get_evalution_config(self):\n",
    "        config = self.config.trained_model\n",
    "\n",
    "        create_directories([config.trained_model_path])\n",
    "\n",
    "        eval_config = {\n",
    "            'test_dir' : Path(config['test_dir']),\n",
    "            'trained_model_path' : Path(config['trained_model_path']),\n",
    "            'model_name' : config['trained_model_name']\n",
    "        }\n",
    "        return eval_config\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-23 22:20:35,282: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/sharadnaik001/Dog_vs_Cat_Classifier \"HTTP/1.1 200 OK\"]\n",
      "Initialized MLflow to track repo \"sharadnaik001/Dog_vs_Cat_Classifier\"\n",
      "[2024-11-23 22:20:35,307: INFO: helpers: Initialized MLflow to track repo \"sharadnaik001/Dog_vs_Cat_Classifier\"]\n",
      "Repository sharadnaik001/Dog_vs_Cat_Classifier initialized!\n",
      "[2024-11-23 22:20:35,321: INFO: helpers: Repository sharadnaik001/Dog_vs_Cat_Classifier initialized!]\n",
      "[2024-11-23 22:20:35,449: WARNING: connectionpool: Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /sharadnaik001/Dog_vs_Cat_Classifier.mlflow/api/2.0/mlflow/runs/create]\n",
      "üèÉ View run bemused-dove-340 at: https://dagshub.com/sharadnaik001/Dog_vs_Cat_Classifier.mlflow/#/experiments/1/runs/f91b86cb28e346f39448d740979c5c02\n",
      "üß™ View experiment at: https://dagshub.com/sharadnaik001/Dog_vs_Cat_Classifier.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import mlflow\n",
    "import dagshub\n",
    "from mlflow import log_metric, log_param\n",
    "from mlflow.keras import log_model\n",
    "from dagshub import DAGsHubLogger\n",
    "\n",
    "from main.d_vs_c import logger\n",
    "\n",
    "dagshub.init(repo_owner='sharadnaik001', repo_name='Dog_vs_Cat_Classifier', mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "with mlflow.start_run():\n",
    "  mlflow.log_param('parameter name', 'value')\n",
    "  mlflow.log_metric('metric name', 1)\n",
    "\n",
    "\n",
    "class Evalution:\n",
    "    def __init__(self, config, params) -> None:\n",
    "        self.config = config\n",
    "        self.params = params\n",
    "\n",
    "    def laod_nd_eval(self):\n",
    "        # checking the test data\n",
    "        test_ds = keras.utils.image_dataset_from_directory(\n",
    "            directory = self.config['test_dir'],\n",
    "            image_size = (256, 256)\n",
    "        )\n",
    "        # print(test_ds.shape)\n",
    "        mdl = os.path.join(self.config['trained_model_path'], self.config['model_name'])\n",
    "\n",
    "        print(f'loading the model..{mdl}')\n",
    "\n",
    "\n",
    "        self.model = tensorflow.keras.models.load_model(mdl)\n",
    "        self.model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "        self.score = self.model.evaluate(test_ds)\n",
    "        logger.info(f'Printing the Model Performance === > Model Accuracy =:> {self.score[1]} and Model loss =:> {self.score[0]}')\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        save_json_file(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "\n",
    "    def implementing_mlflow(self):\n",
    "        tracking_uri = 'https://dagshub.com/sharadnaik001/Dog_vs_Cat_Classifier.mlflow'\n",
    "\n",
    "        mlflow.set_tracking_uri(tracking_uri)\n",
    "        mlflow.set_experiment(\"Dog_vs_Cat_Classifier\")\n",
    "\n",
    "\n",
    "        # Step 2: Enable DAGsHub Logger\n",
    "        dagshub_logger = DAGsHubLogger(metrics_path=\"metrics.json\", hparams_path=\"hparams.json\")\n",
    "        with mlflow.start_run():\n",
    "            # logging the model parameters and configure\n",
    "            log_param('model_name', self.config['model_name'])\n",
    "            log_param(\"image_size\", (256, 256))\n",
    "                                             \n",
    "            # Log metrics: Accuracy and Loss\n",
    "            log_metric(\"accuracy\", self.score[1])\n",
    "            log_metric(\"loss\", self.score[0])\n",
    "      \n",
    "            # Log the model itself (optional, if retraining)\n",
    "            mdl = os.path.join(self.config['trained_model_path'], self.config['model_name'])\n",
    "            self.model = tensorflow.keras.models.load_model(mdl)\n",
    "            log_model(self.model, \"keras_model\")      \n",
    "            # Save the logs to DagsHub\n",
    "            dagshub_logger.log_metrics({\"accuracy\": self.score[1],  \"loss\": self.score[0]})        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts_folder': 'artifacts', 'downloading_data': {'source_dir': 'artifacts/raw_data', 'source_URL': 'karakaggle/kaggle-cat-vs-dog-dataset'}, 'preproccessed_data': {'datasets_dir': 'artifacts/datasets', 'train_dir': 'artifacts/datasets/train', 'test_dir': 'artifacts/datasets/test'}, 'image_categories': ['train/Cat', 'train/Dog', 'test/Cat', 'test/Dog'], 'trained_model': {'trained_model_path': 'artifacts/trained_model', 'datasets_dir': 'artifacts/datasets', 'train_dir': 'artifacts/datasets/train', 'test_dir': 'artifacts/datasets/test', 'trained_model_name': 'model_v-03_cpy.h5'}}\n",
      "{'test_size': 0.2, 'random_state': 42, 'batch_size': 32, 'seed': 128, 'image_size': [256, 256], 'conv_first_layer': 32, 'conv_sec_layer': 64, 'conv_third_layer': 128, 'conv_fourth_layer': 256, 'kernel_size': [3, 3], 'input_shape': [256, 256, 3], 'pool_size': [2, 2], 'strides': 2, 'dropout_rate': 0.25, 'dense_first_layer': 128, 'dense_second_layer': 64, 'output_layer': 1, 'l2_regularization': 0.01, 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'epochs': 1}\n",
      "[2024-11-23 22:20:52,262: INFO: comon_funtn: created directory at: artifacts]\n",
      "[2024-11-23 22:20:52,270: INFO: comon_funtn: created directory at: artifacts/trained_model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4970 files belonging to 2 classes.\n",
      "loading the model..artifacts\\trained_model\\model_v-03_cpy.h5\n",
      "[2024-11-23 22:20:54,537: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Dog_vs_Cat_Classifier\\vir_env\\Lib\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m156/156\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 428ms/step - accuracy: 0.8553 - loss: 0.0823\n",
      "[2024-11-23 22:22:02,843: INFO: 806364281: Printing the Model Performance === > Model Accuracy =:> 0.8651911616325378 and Model loss =:> 0.08226490020751953]\n",
      "[2024-11-23 22:22:02,853: INFO: comon_funtn: json file saved at: scores.json]\n",
      "[2024-11-23 22:22:02,857: INFO: comon_funtn: json file saved at: scores.json]\n",
      "[2024-11-23 22:22:06,524: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/23 22:22:06 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2024/11/23 22:23:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run chill-elk-392 at: https://dagshub.com/sharadnaik001/Dog_vs_Cat_Classifier.mlflow/#/experiments/1/runs/aee22c79aa224020add7af96593a9393\n",
      "üß™ View experiment at: https://dagshub.com/sharadnaik001/Dog_vs_Cat_Classifier.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "obj = ConfigManeger()\n",
    "confi = obj.get_evalution_config()\n",
    "obj2 = Evalution(confi, confi)\n",
    "obj2.laod_nd_eval()\n",
    "obj2.save_score()\n",
    "obj2.implementing_mlflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2076406080.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    export MLFLOW_TRACKING_USERNAME=Sharad Naik\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# export MLFLOW_TRACKING_USERNAME=Sharad Naik\n",
    "# # export MLFLOW_TRACKING_PASSWORD=<DagsHub-password-or-token>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vir_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
